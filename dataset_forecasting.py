from datetime import datetime, timedelta
import numpy as np
import os
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader

class SpeedForecastingDataset(Dataset):
    def __init__(self, data_dir, mode="train", mask_strategy="front"):
        self.seq_len = 8 * 144  # 8 days
        self.mask_len = 1 * 144
        self.pred_len = self.mask_len
        self.mask_strategy = mask_strategy

        if mode in ["train", "valid"]:
            all_files = [f for f in os.listdir(data_dir) if f.endswith(".csv")]
            all_files = [f for f in all_files if "2022-09-28" <= f[:10] <= "2022-10-27"]
        else:  # mode == "test"
            all_files = [f for f in os.listdir(data_dir) if f.endswith(".csv")]
            all_files = [f for f in all_files if "2023-03-02" <= f[:10] <= "2023-03-30"]

        self.data = []
        self.timestamps = []

        for f in all_files:
            df = pd.read_csv(os.path.join(data_dir, f))
            if df.shape != (144, 26):
                continue
            self.data.append(df.iloc[:, 1:].values.astype(np.float32))
            self.timestamps.append(f[:10])

        self.data = np.stack(self.data, axis=0)  # (D, 144, 25)
        self.data = self.data.reshape(-1, 25)

        self.mean = np.nanmean(self.data, axis=0)
        self.std = np.nanstd(self.data, axis=0)
        self.std[self.std == 0] = 1e-6

        self.data = (self.data - self.mean) / self.std
        self.data[np.isnan(self.data)] = 0
        self.data = self.data.reshape(-1, 144, 25)

        self.total_days = len(self.data)
        self.samples = []
        self.sample_dates = []
        self.masked_days = []  # ä¿å­˜æ¯ä¸ªæ ·æœ¬è¢« mask çš„æ—¥æœŸ

        for i in range(self.total_days - 8 + 1):
            self.samples.append(self.data[i:i + 8])
            date_range = tuple(self.timestamps[i:i + 8])
            self.sample_dates.append(date_range)

            if self.mask_strategy == "front":
                self.masked_days.append(date_range[0])
            elif self.mask_strategy == "back":
                self.masked_days.append(date_range[7])
            elif self.mask_strategy == "middle":
                self.masked_days.append(date_range[4])  # ä¸­é—´é‚£ä¸€å¤©ï¼Œç¡®ä¿å­˜åœ¨äº date_range ä¸­

        total = len(self.samples)
        if mode == "train":
            # ä½¿ç”¨å‰ 70% ä½œä¸ºè®­ç»ƒé›†
            self.samples = self.samples[:int(0.7 * total)]
            self.sample_dates = self.sample_dates[:int(0.7 * total)]
            self.masked_days = self.masked_days[:int(0.7 * total)]
        elif mode == "valid":
            # ä½¿ç”¨å‰©ä¸‹ 30% ä½œä¸ºéªŒè¯é›†
            self.samples = self.samples[int(0.7 * total):]
            self.sample_dates = self.sample_dates[int(0.7 * total):]
            self.masked_days = self.masked_days[int(0.7 * total):]
        # ğŸ§ª æ³¨æ„ï¼štest æ¨¡å¼ä¸‹çš„æ•°æ®æ˜¯ 3 æœˆä»½çš„ï¼Œå·²ç»åœ¨æ–‡ä»¶åç­›é€‰ä¸­å¤„ç†ï¼Œæ— éœ€åˆ‡åˆ†

        
        print(f"ğŸ§© Initializing dataset | mode={mode} | mask_strategy={mask_strategy} | total_samples={len(self.samples)}")

        # âœ… Debug masked_day æ˜¯å¦åˆè§„
        print("\nğŸ” [Sanity Check: masked_day]")
        for i in range(min(10, len(self.sample_dates))):
            date_range = self.sample_dates[i]
            masked = self.masked_days[i]
            print(f"Sample {i:2d} | Dates: {date_range} | Masked: {masked}")

            # å¯¹äº front å’Œ back ç­–ç•¥ï¼Œç¡®ä¿ masked_day æ˜¯ç¬¬ä¸€æˆ–æœ€åä¸€å¤©
            if self.mask_strategy in ["front", "back"]:
                assert masked == date_range[0] or masked == date_range[-1], \
                    f"âŒ masked_day '{masked}' ä¸åœ¨ date_range ä¸­: {date_range}"

            # å¯¹äº middle ç­–ç•¥ï¼Œç¡®ä¿ masked_day å°±æ˜¯ date_range ä¸­çš„æŸä¸ªå€¼
            if self.mask_strategy == "middle":
                assert masked in date_range, \
                    f"âŒ middle ç­–ç•¥ç”Ÿæˆäº†ä¸åœ¨èŒƒå›´å†…çš„ masked_day: {masked}, date_range: {date_range}"

        # âœ… æ£€æŸ¥æ•°æ®é›†æ˜¯å¦ä¸ºç©º
        assert len(self.samples) > 0, "âŒ No valid samples found in dataset!"
        assert len(self.samples) == len(self.sample_dates) == len(self.masked_days), \
            f"âŒ æ ·æœ¬æ•°é‡ã€æ—¥æœŸå’Œ masked ä¸ä¸€è‡´ï¼samples={len(self.samples)}, dates={len(self.sample_dates)}, masked={len(self.masked_days)}"


    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        assert len(self.sample_dates[idx]) == 8, f"âŒ sample_dates[{idx}] é•¿åº¦ä¸æ˜¯8ï¼Œè€Œæ˜¯ {len(self.sample_dates[idx])}"
        assert idx < len(self.masked_days), f"âŒ idx={idx} è¶…å‡º masked_days èŒƒå›´ï¼ˆ{len(self.masked_days)}ï¼‰"
        seq = self.samples[idx].reshape(-1, 25)
        observed_data = torch.tensor(seq, dtype=torch.float)
        observed_mask = (~torch.isnan(observed_data)).float()
        gt_mask = observed_mask.clone()

        if self.mask_strategy == "front":
            gt_mask[:self.mask_len, 0] = 0
        elif self.mask_strategy == "back":
            gt_mask[-self.mask_len:, 0] = 0
        elif self.mask_strategy == "middle":
            mid_start = (self.seq_len - self.mask_len) // 2
            gt_mask[mid_start:mid_start + self.mask_len, 0] = 0
        if idx < 5:
            masked_speed_count = (gt_mask[:, 0] == 0).sum().item()
            print(f"ğŸ§ª idx={idx} gt_mask 0-count on speed: {masked_speed_count}")

        timepoints = torch.arange(self.seq_len).float()

        return {
            "observed_data": observed_data,
            "observed_mask": observed_mask,
            "gt_mask": gt_mask,
            "timepoints": timepoints,
            "dates": self.sample_dates[idx],
            "masked_day": self.masked_days[idx]
        }
def get_dataloader(data_path, device, batch_size=8, mask_strategy="back"):
    # åŠ è½½å®Œæ•´è®­ç»ƒé›†ï¼Œæå– mean å’Œ std
    full_train = SpeedForecastingDataset(data_path, mode="train", mask_strategy=mask_strategy)
    mean = torch.tensor(full_train.mean).to(device).float()
    std = torch.tensor(full_train.std).to(device).float()

    # æ‰“å°å‰å‡ ä¸ªæ ·æœ¬çš„ä¿¡æ¯
    for i in range(min(10, len(full_train))):
        print(f"ğŸ“Œ [Train] Sample {i:2d} | Date: {full_train.sample_dates[i]} | Masked: {full_train.masked_days[i]}")

    # âœ… æå–å…¬ç”¨ collate_fn
    def collate_fn(batch):
        return {
            "observed_data": torch.stack([b["observed_data"] for b in batch]),
            "observed_mask": torch.stack([b["observed_mask"] for b in batch]),
            "gt_mask": torch.stack([b["gt_mask"] for b in batch]),
            "timepoints": torch.stack([b["timepoints"] for b in batch]),
            "dates": [b["dates"] for b in batch],
            "masked_day": [b["masked_day"] for b in batch],
        }

    # âœ… æ‰€æœ‰ loader éƒ½ä½¿ç”¨åŒæ ·çš„ collate_fn
    train_loader = DataLoader(full_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)

    valid_loader = DataLoader(
        SpeedForecastingDataset(data_path, mode="valid", mask_strategy=mask_strategy),
        batch_size=batch_size, shuffle=False, collate_fn=collate_fn
    )

    test_loader = DataLoader(
        SpeedForecastingDataset(data_path, mode="test", mask_strategy=mask_strategy),
        batch_size=batch_size, shuffle=False, collate_fn=collate_fn
    )

    # ğŸ§ª æ‰“å°é¦–ä¸ª batch çš„ç»“æ„ç¡®è®¤
    batch = next(iter(train_loader))
    print("ğŸ§ª First batch dates:")
    for i, date_tuple in enumerate(batch["dates"]):
        print(f"Sample {i}: {date_tuple} (len={len(date_tuple)})")
    print(f"ğŸ§ª Train: {len(train_loader.dataset)} samples")
    print(f"ğŸ§ª Valid: {len(valid_loader.dataset)} samples")
    print(f"ğŸ§ª Test : {len(test_loader.dataset)} samples")

    return train_loader, valid_loader, test_loader, std, mean
